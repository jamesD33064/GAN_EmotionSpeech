{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMSw_r1uRm4a"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/espnet/notebook/blob/master/espnet2_tts_realtime_demo.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuhqhYSToxl7"
      },
      "source": [
        "# ESPnet2-TTS realtime demonstration\n",
        "\n",
        "This notebook provides a demonstration of the realtime E2E-TTS using ESPnet2-TTS and ParallelWaveGAN repo.\n",
        "\n",
        "- ESPnet2-TTS: https://github.com/espnet/espnet/tree/master/egs2/TEMPLATE/tts1\n",
        "- ParallelWaveGAN: https://github.com/kan-bayashi/ParallelWaveGAN\n",
        "\n",
        "Author: Tomoki Hayashi ([@kan-bayashi](https://github.com/kan-bayashi))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e_i_gdgAFNJ"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjJ5zkyaoy29",
        "outputId": "009be4e1-ef6d-4d3b-cbab-59b972c7b765"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pypinyin==0.44.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (0.44.0)\n",
            "Requirement already satisfied: parallel_wavegan==0.5.4 in /Users/ash/miniforge3/lib/python3.9/site-packages (0.5.4)\n",
            "Requirement already satisfied: setuptools>=38.5.1 in /Users/ash/miniforge3/lib/python3.9/site-packages (from parallel_wavegan==0.5.4) (59.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from parallel_wavegan==0.5.4) (3.1.0)\n",
            "Requirement already satisfied: librosa>=0.8.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from parallel_wavegan==0.5.4) (0.9.2)\n",
            "Requirement already satisfied: torch>=1.4 in /Users/ash/miniforge3/lib/python3.9/site-packages (from parallel_wavegan==0.5.4) (1.13.0.dev20220921)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /Users/ash/miniforge3/lib/python3.9/site-packages (from parallel_wavegan==0.5.4) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.26.1 in /Users/ash/miniforge3/lib/python3.9/site-packages (from parallel_wavegan==0.5.4) (4.62.3)\n",
            "Requirement already satisfied: yq>=2.10.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from parallel_wavegan==0.5.4) (3.1.0)\n",
            "Requirement already satisfied: tensorboardX>=1.8 in /Users/ash/miniforge3/lib/python3.9/site-packages (from parallel_wavegan==0.5.4) (2.5.1)\n",
            "Requirement already satisfied: gdown in /Users/ash/miniforge3/lib/python3.9/site-packages (from parallel_wavegan==0.5.4) (4.4.0)\n",
            "Requirement already satisfied: kaldiio>=2.14.1 in /Users/ash/miniforge3/lib/python3.9/site-packages (from parallel_wavegan==0.5.4) (2.17.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /Users/ash/miniforge3/lib/python3.9/site-packages (from parallel_wavegan==0.5.4) (0.11.0)\n",
            "Requirement already satisfied: filelock in /Users/ash/miniforge3/lib/python3.9/site-packages (from parallel_wavegan==0.5.4) (3.8.0)\n",
            "Requirement already satisfied: matplotlib>=3.1.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from parallel_wavegan==0.5.4) (3.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from h5py>=2.9.0->parallel_wavegan==0.5.4) (1.22.3)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /Users/ash/miniforge3/lib/python3.9/site-packages (from librosa>=0.8.0->parallel_wavegan==0.5.4) (5.1.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from librosa>=0.8.0->parallel_wavegan==0.5.4) (1.8.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /Users/ash/miniforge3/lib/python3.9/site-packages (from librosa>=0.8.0->parallel_wavegan==0.5.4) (3.0.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from librosa>=0.8.0->parallel_wavegan==0.5.4) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from librosa>=0.8.0->parallel_wavegan==0.5.4) (21.3)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /Users/ash/miniforge3/lib/python3.9/site-packages (from librosa>=0.8.0->parallel_wavegan==0.5.4) (1.1.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /Users/ash/miniforge3/lib/python3.9/site-packages (from librosa>=0.8.0->parallel_wavegan==0.5.4) (0.4.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /Users/ash/miniforge3/lib/python3.9/site-packages (from librosa>=0.8.0->parallel_wavegan==0.5.4) (1.2.0)\n",
            "Requirement already satisfied: numba>=0.45.1 in /Users/ash/miniforge3/lib/python3.9/site-packages (from librosa>=0.8.0->parallel_wavegan==0.5.4) (0.56.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /Users/ash/miniforge3/lib/python3.9/site-packages (from matplotlib>=3.1.0->parallel_wavegan==0.5.4) (3.0.8)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from matplotlib>=3.1.0->parallel_wavegan==0.5.4) (4.33.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/ash/miniforge3/lib/python3.9/site-packages (from matplotlib>=3.1.0->parallel_wavegan==0.5.4) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/ash/miniforge3/lib/python3.9/site-packages (from matplotlib>=3.1.0->parallel_wavegan==0.5.4) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/ash/miniforge3/lib/python3.9/site-packages (from matplotlib>=3.1.0->parallel_wavegan==0.5.4) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from matplotlib>=3.1.0->parallel_wavegan==0.5.4) (9.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from soundfile>=0.10.2->parallel_wavegan==0.5.4) (1.15.0)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from tensorboardX>=1.8->parallel_wavegan==0.5.4) (3.19.6)\n",
            "Requirement already satisfied: typing-extensions in /Users/ash/miniforge3/lib/python3.9/site-packages (from torch>=1.4->parallel_wavegan==0.5.4) (4.3.0)\n",
            "Requirement already satisfied: xmltodict>=0.11.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from yq>=2.10.0->parallel_wavegan==0.5.4) (0.13.0)\n",
            "Requirement already satisfied: argcomplete>=1.8.1 in /Users/ash/miniforge3/lib/python3.9/site-packages (from yq>=2.10.0->parallel_wavegan==0.5.4) (2.0.0)\n",
            "Requirement already satisfied: toml>=0.10.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from yq>=2.10.0->parallel_wavegan==0.5.4) (0.10.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /Users/ash/miniforge3/lib/python3.9/site-packages (from gdown->parallel_wavegan==0.5.4) (4.11.1)\n",
            "Requirement already satisfied: six in /Users/ash/miniforge3/lib/python3.9/site-packages (from gdown->parallel_wavegan==0.5.4) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /Users/ash/miniforge3/lib/python3.9/site-packages (from gdown->parallel_wavegan==0.5.4) (2.27.1)\n",
            "Requirement already satisfied: pycparser in /Users/ash/miniforge3/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.10.2->parallel_wavegan==0.5.4) (2.21)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from numba>=0.45.1->librosa>=0.8.0->parallel_wavegan==0.5.4) (0.39.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from pooch>=1.0->librosa>=0.8.0->parallel_wavegan==0.5.4) (1.4.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from scikit-learn>=0.19.1->librosa>=0.8.0->parallel_wavegan==0.5.4) (3.1.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Users/ash/miniforge3/lib/python3.9/site-packages (from beautifulsoup4->gdown->parallel_wavegan==0.5.4) (2.3.2.post1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/ash/miniforge3/lib/python3.9/site-packages (from requests[socks]->gdown->parallel_wavegan==0.5.4) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ash/miniforge3/lib/python3.9/site-packages (from requests[socks]->gdown->parallel_wavegan==0.5.4) (1.26.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/ash/miniforge3/lib/python3.9/site-packages (from requests[socks]->gdown->parallel_wavegan==0.5.4) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from requests[socks]->gdown->parallel_wavegan==0.5.4) (2.0.12)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/ash/miniforge3/lib/python3.9/site-packages (from requests[socks]->gdown->parallel_wavegan==0.5.4) (1.7.1)\n",
            "Requirement already satisfied: gdown==4.4.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (4.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /Users/ash/miniforge3/lib/python3.9/site-packages (from gdown==4.4.0) (4.11.1)\n",
            "Requirement already satisfied: requests[socks] in /Users/ash/miniforge3/lib/python3.9/site-packages (from gdown==4.4.0) (2.27.1)\n",
            "Requirement already satisfied: six in /Users/ash/miniforge3/lib/python3.9/site-packages (from gdown==4.4.0) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /Users/ash/miniforge3/lib/python3.9/site-packages (from gdown==4.4.0) (4.62.3)\n",
            "Requirement already satisfied: filelock in /Users/ash/miniforge3/lib/python3.9/site-packages (from gdown==4.4.0) (3.8.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Users/ash/miniforge3/lib/python3.9/site-packages (from beautifulsoup4->gdown==4.4.0) (2.3.2.post1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/ash/miniforge3/lib/python3.9/site-packages (from requests[socks]->gdown==4.4.0) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from requests[socks]->gdown==4.4.0) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ash/miniforge3/lib/python3.9/site-packages (from requests[socks]->gdown==4.4.0) (1.26.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/ash/miniforge3/lib/python3.9/site-packages (from requests[socks]->gdown==4.4.0) (3.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/ash/miniforge3/lib/python3.9/site-packages (from requests[socks]->gdown==4.4.0) (1.7.1)\n",
            "Requirement already satisfied: espnet_model_zoo in /Users/ash/miniforge3/lib/python3.9/site-packages (0.1.7)\n",
            "Requirement already satisfied: huggingface-hub in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet_model_zoo) (0.11.1)\n",
            "Requirement already satisfied: requests in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet_model_zoo) (2.27.1)\n",
            "Requirement already satisfied: filelock in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet_model_zoo) (3.8.0)\n",
            "Requirement already satisfied: espnet in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet_model_zoo) (0.10.6)\n",
            "Requirement already satisfied: pandas in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet_model_zoo) (1.4.3)\n",
            "Requirement already satisfied: numpy in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet_model_zoo) (1.22.3)\n",
            "Requirement already satisfied: tqdm in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet_model_zoo) (4.62.3)\n",
            "Requirement already satisfied: pytorch-wpe in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet->espnet_model_zoo) (0.0.1)\n",
            "Requirement already satisfied: sentencepiece in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet->espnet_model_zoo) (0.1.97)\n",
            "Requirement already satisfied: typeguard>=2.7.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet->espnet_model_zoo) (2.13.3)\n",
            "Requirement already satisfied: nltk>=3.4.5 in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet->espnet_model_zoo) (3.8)\n",
            "Requirement already satisfied: ci-sdr in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet->espnet_model_zoo) (0.0.2)\n",
            "Requirement already satisfied: PyYAML>=5.1.2 in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet->espnet_model_zoo) (6.0)\n",
            "Requirement already satisfied: pyworld>=0.2.10 in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet->espnet_model_zoo) (0.3.2)\n",
            "Requirement already satisfied: configargparse>=1.2.1 in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet->espnet_model_zoo) (1.5.3)\n",
            "Requirement already satisfied: torch-complex in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet->espnet_model_zoo) (0.4.3)\n",
            "Requirement already satisfied: librosa>=0.8.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet->espnet_model_zoo) (0.9.2)\n",
            "Requirement already satisfied: ctc-segmentation<1.8,>=1.6.6 in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet->espnet_model_zoo) (1.7.4)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet->espnet_model_zoo) (0.11.0)\n",
            "Requirement already satisfied: torch>=1.3.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet->espnet_model_zoo) (1.13.0.dev20220921)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet->espnet_model_zoo) (1.8.0)\n",
            "Requirement already satisfied: kaldiio>=2.17.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet->espnet_model_zoo) (2.17.2)\n",
            "Requirement already satisfied: pypinyin<=0.44.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet->espnet_model_zoo) (0.44.0)\n",
            "Requirement already satisfied: setuptools>=38.5.1 in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet->espnet_model_zoo) (59.8.0)\n",
            "Requirement already satisfied: espnet-tts-frontend in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet->espnet_model_zoo) (0.0.3)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet->espnet_model_zoo) (3.1.0)\n",
            "Requirement already satisfied: humanfriendly in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet->espnet_model_zoo) (10.0)\n",
            "Requirement already satisfied: jamo==0.4.1 in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet->espnet_model_zoo) (0.4.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /Users/ash/miniforge3/lib/python3.9/site-packages (from huggingface-hub->espnet_model_zoo) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ash/miniforge3/lib/python3.9/site-packages (from huggingface-hub->espnet_model_zoo) (4.3.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/ash/miniforge3/lib/python3.9/site-packages (from pandas->espnet_model_zoo) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/ash/miniforge3/lib/python3.9/site-packages (from pandas->espnet_model_zoo) (2.8.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/ash/miniforge3/lib/python3.9/site-packages (from requests->espnet_model_zoo) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from requests->espnet_model_zoo) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/ash/miniforge3/lib/python3.9/site-packages (from requests->espnet_model_zoo) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ash/miniforge3/lib/python3.9/site-packages (from requests->espnet_model_zoo) (1.26.8)\n",
            "Requirement already satisfied: Cython in /Users/ash/miniforge3/lib/python3.9/site-packages (from ctc-segmentation<1.8,>=1.6.6->espnet->espnet_model_zoo) (0.29.32)\n",
            "Requirement already satisfied: numba>=0.45.1 in /Users/ash/miniforge3/lib/python3.9/site-packages (from librosa>=0.8.0->espnet->espnet_model_zoo) (0.56.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /Users/ash/miniforge3/lib/python3.9/site-packages (from librosa>=0.8.0->espnet->espnet_model_zoo) (0.4.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /Users/ash/miniforge3/lib/python3.9/site-packages (from librosa>=0.8.0->espnet->espnet_model_zoo) (1.2.0)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /Users/ash/miniforge3/lib/python3.9/site-packages (from librosa>=0.8.0->espnet->espnet_model_zoo) (5.1.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /Users/ash/miniforge3/lib/python3.9/site-packages (from librosa>=0.8.0->espnet->espnet_model_zoo) (3.0.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from librosa>=0.8.0->espnet->espnet_model_zoo) (1.6.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /Users/ash/miniforge3/lib/python3.9/site-packages (from librosa>=0.8.0->espnet->espnet_model_zoo) (1.1.2)\n",
            "Requirement already satisfied: click in /Users/ash/miniforge3/lib/python3.9/site-packages (from nltk>=3.4.5->espnet->espnet_model_zoo) (8.1.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/ash/miniforge3/lib/python3.9/site-packages (from nltk>=3.4.5->espnet->espnet_model_zoo) (2022.10.31)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/ash/miniforge3/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub->espnet_model_zoo) (3.0.8)\n",
            "Requirement already satisfied: six>=1.5 in /Users/ash/miniforge3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->espnet_model_zoo) (1.15.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from soundfile>=0.10.2->espnet->espnet_model_zoo) (1.15.0)\n",
            "Requirement already satisfied: einops in /Users/ash/miniforge3/lib/python3.9/site-packages (from ci-sdr->espnet->espnet_model_zoo) (0.6.0)\n",
            "Requirement already satisfied: inflect>=1.0.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet-tts-frontend->espnet->espnet_model_zoo) (6.0.2)\n",
            "Requirement already satisfied: unidecode>=1.0.22 in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet-tts-frontend->espnet->espnet_model_zoo) (1.3.6)\n",
            "Requirement already satisfied: g2p-en in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet-tts-frontend->espnet->espnet_model_zoo) (2.1.0)\n",
            "Requirement already satisfied: jaconv in /Users/ash/miniforge3/lib/python3.9/site-packages (from espnet-tts-frontend->espnet->espnet_model_zoo) (0.3.1)\n",
            "Requirement already satisfied: pycparser in /Users/ash/miniforge3/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.10.2->espnet->espnet_model_zoo) (2.21)\n",
            "Requirement already satisfied: pydantic>=1.9.1 in /Users/ash/miniforge3/lib/python3.9/site-packages (from inflect>=1.0.0->espnet-tts-frontend->espnet->espnet_model_zoo) (1.10.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from numba>=0.45.1->librosa>=0.8.0->espnet->espnet_model_zoo) (0.39.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from pooch>=1.0->librosa>=0.8.0->espnet->espnet_model_zoo) (1.4.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ash/miniforge3/lib/python3.9/site-packages (from scikit-learn>=0.19.1->librosa>=0.8.0->espnet->espnet_model_zoo) (3.1.0)\n",
            "Requirement already satisfied: distance>=0.1.3 in /Users/ash/miniforge3/lib/python3.9/site-packages (from g2p-en->espnet-tts-frontend->espnet->espnet_model_zoo) (0.1.3)\n"
          ]
        }
      ],
      "source": [
        "# NOTE: pip shows imcompatible errors due to preinstalled libraries but you do not need to care\n",
        "!pip install -q espnet==0.10.6\n",
        "# !pip install pyopenjtalk==0.2 \n",
        "!pip install pypinyin==0.44.0 \n",
        "!pip install parallel_wavegan==0.5.4 \n",
        "!pip install gdown==4.4.0 \n",
        "!pip install espnet_model_zoo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYLn3bL-qQjN"
      },
      "source": [
        "## Single speaker model demo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as4iFXid0m4f"
      },
      "source": [
        "### Model Selection\n",
        "\n",
        "Please select model: English, Japanese, and Mandarin are supported.\n",
        "\n",
        "You can try end-to-end text2wav model & combination of text2mel and vocoder.  \n",
        "If you use text2wav model, you do not need to use vocoder (automatically disabled).\n",
        "\n",
        "**Text2wav models**:\n",
        "- VITS\n",
        "\n",
        "**Text2mel models**:\n",
        "- Tacotron2\n",
        "- Transformer-TTS\n",
        "- (Conformer) FastSpeech\n",
        "- (Conformer) FastSpeech2\n",
        "\n",
        "**Vocoders**:\n",
        "- Parallel WaveGAN\n",
        "- Multi-band MelGAN\n",
        "- HiFiGAN\n",
        "- Style MelGAN.\n",
        "\n",
        "\n",
        "> The terms of use follow that of each corpus. We use the following corpora:\n",
        "- `ljspeech_*`: LJSpeech dataset \n",
        "  - https://keithito.com/LJ-Speech-Dataset/\n",
        "- `jsut_*`: JSUT corpus\n",
        "  - https://sites.google.com/site/shinnosuketakamichi/publication/jsut\n",
        "- `jvs_*`: JVS corpus + JSUT corpus\n",
        "  - https://sites.google.com/site/shinnosuketakamichi/research-topics/jvs_corpus\n",
        "  - https://sites.google.com/site/shinnosuketakamichi/publication/jsut\n",
        "- `tsukuyomi_*`: つくよみちゃんコーパス + JSUT corpus\n",
        "  - https://tyc.rei-yumesaki.net/material/corpus/\n",
        "  - https://sites.google.com/site/shinnosuketakamichi/publication/jsut\n",
        "- `csmsc_*`: Chinese Standard Mandarin Speech Corpus\n",
        "  - https://www.data-baker.com/open_source.html \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "J-Bvca5mE7bT"
      },
      "outputs": [],
      "source": [
        "#@title Choose English model { run: \"auto\" }\n",
        "lang = 'English'\n",
        "tag = 'kan-bayashi/ljspeech_vits' #@param [\"kan-bayashi/ljspeech_tacotron2\", \"kan-bayashi/ljspeech_fastspeech\", \"kan-bayashi/ljspeech_fastspeech2\", \"kan-bayashi/ljspeech_conformer_fastspeech2\", \"kan-bayashi/ljspeech_joint_finetune_conformer_fastspeech2_hifigan\", \"kan-bayashi/ljspeech_joint_train_conformer_fastspeech2_hifigan\", \"kan-bayashi/ljspeech_vits\"] {type:\"string\"}\n",
        "vocoder_tag = \"none\" #@param [\"none\", \"parallel_wavegan/ljspeech_parallel_wavegan.v1\", \"parallel_wavegan/ljspeech_full_band_melgan.v2\", \"parallel_wavegan/ljspeech_multi_band_melgan.v2\", \"parallel_wavegan/ljspeech_hifigan.v1\", \"parallel_wavegan/ljspeech_style_melgan.v1\"] {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2BczOBfvE7bU"
      },
      "outputs": [],
      "source": [
        "#@title Choose Japanese model { run: \"auto\" }\n",
        "lang = 'Japanese'\n",
        "tag = 'kan-bayashi/jsut_full_band_vits_prosody' #@param [\"kan-bayashi/jsut_tacotron2\", \"kan-bayashi/jsut_transformer\", \"kan-bayashi/jsut_fastspeech\", \"kan-bayashi/jsut_fastspeech2\", \"kan-bayashi/jsut_conformer_fastspeech2\", \"kan-bayashi/jsut_conformer_fastspeech2_accent\", \"kan-bayashi/jsut_conformer_fastspeech2_accent_with_pause\", \"kan-bayashi/jsut_vits_accent_with_pause\", \"kan-bayashi/jsut_full_band_vits_accent_with_pause\", \"kan-bayashi/jsut_tacotron2_prosody\", \"kan-bayashi/jsut_transformer_prosody\", \"kan-bayashi/jsut_conformer_fastspeech2_tacotron2_prosody\", \"kan-bayashi/jsut_vits_prosody\", \"kan-bayashi/jsut_full_band_vits_prosody\", \"kan-bayashi/jvs_jvs010_vits_prosody\", \"kan-bayashi/tsukuyomi_full_band_vits_prosody\"] {type:\"string\"}\n",
        "vocoder_tag = 'none' #@param [\"none\", \"parallel_wavegan/jsut_parallel_wavegan.v1\", \"parallel_wavegan/jsut_multi_band_melgan.v2\", \"parallel_wavegan/jsut_style_melgan.v1\", \"parallel_wavegan/jsut_hifigan.v1\"] {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "k0jWteQ1E7bU"
      },
      "outputs": [],
      "source": [
        "#@title Choose Mandarin model { run: \"auto\" }\n",
        "lang = 'Mandarin'\n",
        "tag = 'kan-bayashi/csmsc_full_band_vits' #@param [\"kan-bayashi/csmsc_tacotron2\", \"kan-bayashi/csmsc_transformer\", \"kan-bayashi/csmsc_fastspeech\", \"kan-bayashi/csmsc_fastspeech2\", \"kan-bayashi/csmsc_conformer_fastspeech2\", \"kan-bayashi/csmsc_vits\", \"kan-bayashi/csmsc_full_band_vits\"] {type: \"string\"}\n",
        "vocoder_tag = \"none\" #@param [\"none\", \"parallel_wavegan/csmsc_parallel_wavegan.v1\", \"parallel_wavegan/csmsc_multi_band_melgan.v2\", \"parallel_wavegan/csmsc_hifigan.v1\", \"parallel_wavegan/csmsc_style_melgan.v1\"] {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9S-SFPe0z0w"
      },
      "source": [
        "### Model Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z64fD2UgjJ6Q",
        "outputId": "2522156b-00e9-4554-b0c1-2ad625bced24"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'espnet2'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/ash/Documents/GitHub/GAN_EmotionSpeech/dataset/espnet2_tts_demo.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ash/Documents/GitHub/GAN_EmotionSpeech/dataset/espnet2_tts_demo.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mespnet2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbin\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtts_inference\u001b[39;00m \u001b[39mimport\u001b[39;00m Text2Speech\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ash/Documents/GitHub/GAN_EmotionSpeech/dataset/espnet2_tts_demo.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mespnet2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m str_or_none\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ash/Documents/GitHub/GAN_EmotionSpeech/dataset/espnet2_tts_demo.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m text2speech \u001b[39m=\u001b[39m Text2Speech\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ash/Documents/GitHub/GAN_EmotionSpeech/dataset/espnet2_tts_demo.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     model_tag\u001b[39m=\u001b[39mstr_or_none(tag),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ash/Documents/GitHub/GAN_EmotionSpeech/dataset/espnet2_tts_demo.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     vocoder_tag\u001b[39m=\u001b[39mstr_or_none(vocoder_tag),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ash/Documents/GitHub/GAN_EmotionSpeech/dataset/espnet2_tts_demo.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     noise_scale_dur\u001b[39m=\u001b[39m\u001b[39m0.333\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ash/Documents/GitHub/GAN_EmotionSpeech/dataset/espnet2_tts_demo.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m )\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'espnet2'"
          ]
        }
      ],
      "source": [
        "from espnet2.bin.tts_inference import Text2Speech\n",
        "from espnet2.utils.types import str_or_none\n",
        "\n",
        "text2speech = Text2Speech.from_pretrained(\n",
        "    model_tag=str_or_none(tag),\n",
        "    vocoder_tag=str_or_none(vocoder_tag),\n",
        "    device=\"cuda\",\n",
        "    # Only for Tacotron 2 & Transformer\n",
        "    threshold=0.5,\n",
        "    # Only for Tacotron 2\n",
        "    minlenratio=0.0,\n",
        "    maxlenratio=10.0,\n",
        "    use_att_constraint=False,\n",
        "    backward_window=1,\n",
        "    forward_window=3,\n",
        "    # Only for FastSpeech & FastSpeech2 & VITS\n",
        "    speed_control_alpha=1.0,\n",
        "    # Only for VITS\n",
        "    noise_scale=0.333,\n",
        "    noise_scale_dur=0.333,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMaT0Zev021a"
      },
      "source": [
        "### Synthesis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "vrRM57hhgtHy",
        "outputId": "2c395f1c-8961-49e4-cf07-0cd6161e09f2"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/ash/Documents/GitHub/GAN_EmotionSpeech/dataset/espnet2_tts_demo.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ash/Documents/GitHub/GAN_EmotionSpeech/dataset/espnet2_tts_demo.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ash/Documents/GitHub/GAN_EmotionSpeech/dataset/espnet2_tts_demo.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ash/Documents/GitHub/GAN_EmotionSpeech/dataset/espnet2_tts_demo.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# decide the input sentence by yourself\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ash/Documents/GitHub/GAN_EmotionSpeech/dataset/espnet2_tts_demo.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInput your favorite sentence in \u001b[39m\u001b[39m{\u001b[39;00mlang\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import torch\n",
        "\n",
        "# decide the input sentence by yourself\n",
        "print(f\"Input your favorite sentence in {lang}.\")\n",
        "x = input()\n",
        "\n",
        "# synthesis\n",
        "with torch.no_grad():\n",
        "    start = time.time()\n",
        "    wav = text2speech(x)[\"wav\"]\n",
        "rtf = (time.time() - start) / (len(wav) / text2speech.fs)\n",
        "print(f\"RTF = {rtf:5f}\")\n",
        "\n",
        "# let us listen to generated samples\n",
        "from IPython.display import display, Audio\n",
        "display(Audio(wav.view(-1).cpu().numpy(), rate=text2speech.fs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TTAygALqY6T"
      },
      "source": [
        "## Multi-speaker Model Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSEZYh22n4gn"
      },
      "source": [
        "### Model Selection\n",
        "\n",
        "Now we provide only English multi-speaker pretrained model.\n",
        "\n",
        "> The terms of use follow that of each corpus. We use the following corpora:\n",
        "- `libritts_*`: LibriTTS corpus\n",
        "  - http://www.openslr.org/60\n",
        "- `vctk_*`: English Multi-speaker Corpus for CSTR Voice Cloning Toolkit\n",
        "  - http://www.udialogue.org/download/cstr-vctk-corpus.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSKLmDN9E7bW"
      },
      "outputs": [],
      "source": [
        "#@title English multi-speaker pretrained model { run: \"auto\" }\n",
        "lang = 'English'\n",
        "tag = 'kan-bayashi/vctk_full_band_multi_spk_vits' #@param [\"kan-bayashi/vctk_gst_tacotron2\", \"kan-bayashi/vctk_gst_transformer\", \"kan-bayashi/vctk_xvector_tacotron2\", \"kan-bayashi/vctk_xvector_transformer\", \"kan-bayashi/vctk_xvector_conformer_fastspeech2\", \"kan-bayashi/vctk_gst+xvector_tacotron2\", \"kan-bayashi/vctk_gst+xvector_transformer\", \"kan-bayashi/vctk_gst+xvector_conformer_fastspeech2\", \"kan-bayashi/vctk_multi_spk_vits\", \"kan-bayashi/vctk_full_band_multi_spk_vits\", \"kan-bayashi/libritts_xvector_transformer\", \"kan-bayashi/libritts_xvector_conformer_fastspeech2\", \"kan-bayashi/libritts_gst+xvector_transformer\", \"kan-bayashi/libritts_gst+xvector_conformer_fastspeech2\", \"kan-bayashi/libritts_xvector_vits\"] {type:\"string\"}\n",
        "vocoder_tag = \"none\" #@param [\"none\", \"parallel_wavegan/vctk_parallel_wavegan.v1.long\", \"parallel_wavegan/vctk_multi_band_melgan.v2\", \"parallel_wavegan/vctk_style_melgan.v1\", \"parallel_wavegan/vctk_hifigan.v1\", \"parallel_wavegan/libritts_parallel_wavegan.v1.long\", \"parallel_wavegan/libritts_multi_band_melgan.v2\", \"parallel_wavegan/libritts_hifigan.v1\", \"parallel_wavegan/libritts_style_melgan.v1\"] {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcshmgYpoVzh"
      },
      "source": [
        "### Model Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfJFD4QroNhJ"
      },
      "outputs": [],
      "source": [
        "from espnet2.bin.tts_inference import Text2Speech\n",
        "from espnet2.utils.types import str_or_none\n",
        "\n",
        "text2speech = Text2Speech.from_pretrained(\n",
        "    model_tag=str_or_none(tag),\n",
        "    vocoder_tag=str_or_none(vocoder_tag),\n",
        "    device=\"cuda\",\n",
        "    # Only for Tacotron 2 & Transformer\n",
        "    threshold=0.5,\n",
        "    # Only for Tacotron 2\n",
        "    minlenratio=0.0,\n",
        "    maxlenratio=10.0,\n",
        "    use_att_constraint=False,\n",
        "    backward_window=1,\n",
        "    forward_window=3,\n",
        "    # Only for FastSpeech & FastSpeech2 & VITS\n",
        "    speed_control_alpha=1.0,\n",
        "    # Only for VITS\n",
        "    noise_scale=0.333,\n",
        "    noise_scale_dur=0.333,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdaMNwrtuZhY"
      },
      "source": [
        "### Speaker selection\n",
        "\n",
        "For multi-speaker model, we need to provide X-vector and/or the reference speech to decide the speaker characteristics.  \n",
        "For X-vector, you can select the speaker from the dumped x-vectors.  \n",
        "For the reference speech, you can use any speech but please make sure the sampling rate is matched."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzoAd1rgObcP"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import kaldiio\n",
        "\n",
        "# Get model directory path\n",
        "from espnet_model_zoo.downloader import ModelDownloader\n",
        "d = ModelDownloader()\n",
        "model_dir = os.path.dirname(d.download_and_unpack(tag)[\"train_config\"])\n",
        "\n",
        "# X-vector selection\n",
        "spembs = None\n",
        "if text2speech.use_spembs:\n",
        "    xvector_ark = [p for p in glob.glob(f\"{model_dir}/../../dump/**/spk_xvector.ark\", recursive=True) if \"tr\" in p][0]\n",
        "    xvectors = {k: v for k, v in kaldiio.load_ark(xvector_ark)}\n",
        "    spks = list(xvectors.keys())\n",
        "\n",
        "    # randomly select speaker\n",
        "    random_spk_idx = np.random.randint(0, len(spks))\n",
        "    spk = spks[random_spk_idx]\n",
        "    spembs = xvectors[spk]\n",
        "    print(f\"selected spk: {spk}\")\n",
        "\n",
        "# Speaker ID selection\n",
        "sids = None\n",
        "if text2speech.use_sids:\n",
        "    spk2sid = glob.glob(f\"{model_dir}/../../dump/**/spk2sid\", recursive=True)[0]\n",
        "    with open(spk2sid) as f:\n",
        "        lines = [line.strip() for line in f.readlines()]\n",
        "    sid2spk = {int(line.split()[1]): line.split()[0] for line in lines}\n",
        "    \n",
        "    # randomly select speaker\n",
        "    sids = np.array(np.random.randint(1, len(sid2spk)))\n",
        "    spk = sid2spk[int(sids)]\n",
        "    print(f\"selected spk: {spk}\")\n",
        "\n",
        "# Reference speech selection for GST\n",
        "speech = None\n",
        "if text2speech.use_speech:\n",
        "    # you can change here to load your own reference speech\n",
        "    # e.g.\n",
        "    # import soundfile as sf\n",
        "    # speech, fs = sf.read(\"/path/to/reference.wav\")\n",
        "    # speech = torch.from_numpy(speech).float()\n",
        "    speech = torch.randn(50000,) * 0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6G-1YW9ocYV"
      },
      "source": [
        "### Synthesis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o87zK1NLobne"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "\n",
        "# decide the input sentence by yourself\n",
        "print(f\"Input your favorite sentence in {lang}.\")\n",
        "x = input()\n",
        "\n",
        "# synthesis\n",
        "with torch.no_grad():\n",
        "    start = time.time()\n",
        "    wav = text2speech(x, speech=speech, spembs=spembs, sids=sids)[\"wav\"]\n",
        "rtf = (time.time() - start) / (len(wav) / text2speech.fs)\n",
        "print(f\"RTF = {rtf:5f}\")\n",
        "\n",
        "# let us listen to generated samples\n",
        "from IPython.display import display, Audio\n",
        "display(Audio(wav.view(-1).cpu().numpy(), rate=text2speech.fs))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "espnet2_tts_demo",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
